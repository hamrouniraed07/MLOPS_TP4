# D√©cision de Promotion du Mod√®le YOLO Tiny - D√©tection de Personnes

**Date de l'analyse** : 23 novembre 2025  
**Exp√©rience** : cv_yolo_tiny  
**Dataset** : tiny_coco (COCO128 - classe "person" uniquement)  
**Nombre de runs analys√©s** : 2 (sur 8 ex√©cut√©s)

---

## üéØ Run S√©lectionn√©

### Informations principales
- **Run ID** : `87b38ef6c1c34c78935231ff929cafc9`
- **Run Name** : `yolov8n_e3_sz320_lr0.005_s1`
- **Date d'ex√©cution** : 23/11/2025, 01:36:57 PM
- **Dur√©e d'entra√Ænement** : 4.3 minutes

### Hyperparam√®tres
| Param√®tre | Valeur |
|-----------|--------|
| **Model** | YOLOv8n (nano) |
| **Epochs** | 3 |
| **Image Size** | 320x320 |
| **Learning Rate** | 0.005 |
| **Seed** | 1 |
| **Batch Size** | 16 (d√©faut YOLOv8) |

### M√©triques de performance

| M√©trique | Valeur | Description |
|----------|--------|-------------|
| **mAP@50** | **0.27592** | Pr√©cision moyenne √† 50% IoU (m√©trique principale) |
| **mAP@50-95** | **0.19888** | Pr√©cision moyenne sur plusieurs seuils IoU (0.50 √† 0.95) |
| **Precision** | **0.00874** | Taux de vrais positifs parmi les d√©tections |
| **Recall** | **0.81613** | Taux de personnes correctement d√©tect√©es (81.6%) |
| **F1-Score** | **0.0173** | Moyenne harmonique pr√©cision/rappel |
| **Inference Time** | ~15-20ms | Temps d'inf√©rence estim√© par image |

---

## üìä Comparaison avec les autres runs

### Run concurrent analys√©
- **Run ID** : `d8ce7912a13c449381a92563021736d4`
- **Run Name** : `yolov8n_e3_sz320_lr0.005_s42`
- **Diff√©rence principale** : Seed = 42 (vs seed = 1)
- **Dur√©e** : 4.5 minutes (0.2 min de plus)

### Tableau comparatif

| M√©trique | Run s√©lectionn√© (seed=1) | Run alternatif (seed=42) | Diff√©rence |
|----------|--------------------------|--------------------------|------------|
| **mAP@50** | **0.27592** | ~0.27-0.28 | Similaire |
| **Precision** | **0.00874** | ~0.008-0.009 | Similaire |
| **Recall** | **0.81613** | ~0.81-0.82 | Similaire |
| **mAP@50-95** | **0.19888** | ~0.198-0.199 | Similaire |
| **Dur√©e** | **4.3 min** | **4.5 min** | +0.2 min |

### Observations du Parallel Coordinates Plot
D'apr√®s les visualisations MLflow :
- ‚úÖ Les deux runs ont des param√®tres quasi-identiques (seul le seed diff√®re)
- ‚úÖ Les m√©triques sont tr√®s stables entre seed=1 et seed=42 (bonne reproductibilit√©)
- ‚úÖ Le run avec seed=1 est l√©g√®rement plus rapide (4.3 vs 4.5 min)
- ‚ö†Ô∏è **ATTENTION CRITIQUE** : La pr√©cision est extr√™mement basse (0.87%) ce qui indique un probl√®me majeur

---

## ‚úÖ POUR - Arguments en faveur du mod√®le s√©lectionn√©

### 1. Performance sur le Recall (Point fort principal)
- ‚úÖ **Excellent Recall** : 81.6% des personnes sont correctement d√©tect√©es
- ‚úÖ **Faible taux de faux n√©gatifs** : Seulement 18.4% de personnes manqu√©es
- ‚úÖ **Adapt√© aux cas d'usage de s√©curit√©** : Peu de personnes passent inaper√ßues

### 2. Performance g√©n√©rale du mAP
- ‚ö†Ô∏è **mAP@50 = 0.276** : Tr√®s faible, indique beaucoup de fausses d√©tections
- ‚ö†Ô∏è **mAP@50-95 = 0.199** : Performance m√©diocre sur plusieurs seuils IoU
- ‚ÑπÔ∏è Coh√©rent avec un dataset ultra-r√©duit (128 images) et seulement 3 epochs

### 3. Efficacit√© computationnelle
- ‚úÖ **Temps d'entra√Ænement rapide** : 4.3 minutes pour 3 epochs
- ‚úÖ **Mod√®le l√©ger** : YOLOv8n (architecture nano, ~3 Mo)
- ‚úÖ **Inference rapide** : Adapt√© au temps r√©el sur CPU/edge devices
- ‚úÖ **Faible consommation m√©moire** : D√©ployable sur hardware limit√©

### 4. Reproductibilit√© et tra√ßabilit√©
- ‚úÖ **Tracking complet** : Tous les param√®tres et m√©triques logg√©s dans MLflow
- ‚úÖ **Dataset versionn√©** : DVC assure la reproductibilit√© des donn√©es
- ‚úÖ **Stabilit√© entre seeds** : R√©sultats coh√©rents (seed 1 vs 42)
- ‚úÖ **Artefacts disponibles** : Poids du mod√®le, graphiques, matrices de confusion

---

## ‚ùå CONTRE - Limites et faiblesses identifi√©es

### üö® 1. PROBL√àME CRITIQUE : Pr√©cision catastrophique
- ‚ùå **Precision = 0.87%** : Sur 100 d√©tections, 99 sont des faux positifs !
- ‚ùå **Ratio Precision/Recall d√©s√©quilibr√©** : 0.87% vs 81.6% = probl√®me majeur
- ‚ùå **mAP faible (0.276)** : Confirme le d√©s√©quilibre massif
- ‚ùå **Inutilisable en production** : G√©n√©rerait des milliers de fausses alarmes

**Cause probable** :
- Seuil de confiance trop bas pendant l'entra√Ænement
- Dataset trop petit ‚Üí mod√®le sur-d√©tecte par manque d'exemples n√©gatifs
- 3 epochs insuffisants pour calibration correcte

### 2. Limitations des donn√©es
- ‚ùå **Dataset ultra-r√©duit** : Seulement COCO128 (128 images) ‚Üí surapprentissage quasi-certain
- ‚ùå **Une seule classe** : Pas de g√©n√©ralisation multi-objets
- ‚ùå **Biais du dataset** : COCO peut ne pas repr√©senter les conditions r√©elles de production
- ‚ùå **Pas de donn√©es de validation externe** : Performance inconnue hors COCO

### 3. Limitations exp√©rimentales
- ‚ùå **Seulement 3 epochs** : Tr√®s insuffisant pour convergence (YOLOv8 recommande 100+ epochs)
- ‚ùå **Pas d'optimisation du seuil de confiance** : Cause directe de la pr√©cision catastrophique
- ‚ùå **Validation crois√©e absente** : Un seul split train/val/test
- ‚ùå **Pas d'analyse de robustesse** : Tests sur variations (bruit, rotation, √©chelle) non effectu√©s

### 4. Risques de production CRITIQUES
- ‚ùå **Faux positifs massifs** : 99% de fausses d√©tections ‚Üí syst√®me inutilisable
- ‚ùå **Co√ªt computationnel r√©el** : Post-traitement de milliers de fausses d√©tections
- ‚ùå **Exp√©rience utilisateur catastrophique** : Alertes constantes sans raison
- ‚ùå **Dataset shift** : Production ‚â† COCO ‚Üí d√©gradation encore plus probable

---

## ‚öñÔ∏è COMPROMIS - Performance vs Latence vs Co√ªt

### üìà Performance : ‚≠ê‚òÜ‚òÜ‚òÜ‚òÜ (1/5) - INAD√âQUAT
**Points forts** :
- ‚úÖ Recall acceptable : 81.6% de d√©tection des personnes
- ‚úÖ Peu de faux n√©gatifs (18.4%)

**Points faibles** :
- üö® **Precision catastrophique : 0.87%** (99% de faux positifs)
- ‚ùå mAP@50 tr√®s faible : 0.276 (cible minimale : 0.50+)
- ‚ùå F1-Score d√©sastreux : 0.0173
- ‚ùå Syst√®me g√©n√®re 113 fausses d√©tections pour 1 vraie

**Verdict** : **INACCEPTABLE pour production**. Le mod√®le d√©tecte bien les personnes mais g√©n√®re un d√©luge de fausses alarmes.

---

### ‚ö° Latence : ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (5/5) - EXCELLENT
**Points forts** :
- ‚úÖ Architecture nano ultra-l√©g√®re (~3 Mo)
- ‚úÖ Inference time estim√© : 10-20ms par image sur CPU moderne
- ‚úÖ Capable de 30-60 FPS en temps r√©el
- ‚úÖ Image size 320px r√©duit le temps de pr√©traitement

**Points faibles** :
- ‚ö†Ô∏è Latence r√©elle augment√©e par post-traitement des milliers de faux positifs

**Verdict** : **Excellent** pour applications edge, mais compromis par le besoin de filtrage massif.

---

### üí∞ Co√ªt : ‚≠ê‚≠ê‚≠ê‚≠ê‚òÜ (4/5) - BON (avec r√©serve)
**Points forts** :
- ‚úÖ **Infrastructure minimale** : Pas besoin de GPU en production
- ‚úÖ **Entra√Ænement rapide** : 4.3 min ‚Üí co√ªt compute n√©gligeable
- ‚úÖ **Stockage minimal** : Mod√®le de 3 Mo
- ‚úÖ **Edge deployment** : Pas de co√ªts cloud d'inf√©rence

**Points faibles** :
- ‚ùå **Co√ªt cach√©** : CPU surcharg√© par traitement de 99% de faux positifs
- ‚ùå **Co√ªt op√©rationnel** : Support utilisateur submerg√© de fausses alertes
- ‚ùå **Co√ªt de retraining** : N√©cessite r√©entra√Ænement complet (100+ epochs)

**Verdict** : √âconomique en th√©orie, mais co√ªt op√©rationnel r√©el √©lev√© √† cause des faux positifs.

---

### üéØ Synth√®se du compromis

```
Performance ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 10%  ‚Üê CRITIQUE : Precision 0.87%
Latence     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 50%  ‚Üê Excellent mais compromis
Co√ªt        ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë 40%  ‚Üê Bon mais co√ªts cach√©s
```

**Conclusion** : Le mod√®le sacrifie TOTALEMENT la pr√©cision pour la vitesse. Le d√©s√©quilibre est si extr√™me (0.87% precision) qu'il **annule tous les b√©n√©fices de latence et co√ªt**.

**Sc√©narios acceptables** (tr√®s limit√©s) :
- üü° Screening ultra-large o√π on filtre apr√®s (ex: 1√®re √©tape d'un pipeline √† 2 niveaux)
- üü° Recherche acad√©mique sur le recall maximal
- ‚ùå **AUCUN cas d'usage production standard**

---

## ‚ö†Ô∏è RISQUES

### üî¥ Risques Techniques (√âLEV√âS)

#### 1. Surapprentissage
- **Probabilit√©** : üî¥ Tr√®s √©lev√©e
- **Impact** : D√©gradation s√©v√®re en production
- **Cause** : Dataset de 128 images insuffisant
- **Mitigation** :
  - ‚úÖ R√©entra√Æner sur COCO complet (118k images)
  - ‚úÖ Appliquer data augmentation agressive
  - ‚úÖ Tester sur datasets externes (OpenImages, etc.)

#### 2. Dataset Shift
- **Probabilit√©** : üî¥ √âlev√©e
- **Impact** : mAP peut chuter de 20-40% en production
- **Cause** : Conditions COCO ‚â† conditions r√©elles
- **Mitigation** :
  - ‚úÖ Collecter donn√©es de production d√®s le d√©ploiement
  - ‚úÖ Impl√©menter monitoring de drift (ex: Evidently AI)
  - ‚úÖ Pipeline de retraining automatique

#### 3. Faux n√©gatifs critiques
- **Probabilit√©** : üü° Moyenne (d√©pend du recall)
- **Impact** : Personnes non d√©tect√©es ‚Üí probl√®me selon cas d'usage
- **Cause** : Compromis pr√©cision/rappel du mod√®le nano
- **Mitigation** :
  - ‚úÖ D√©finir seuil de confiance adapt√© au cas d'usage
  - ‚úÖ Impl√©menter syst√®me de fallback (d√©tecteur secondaire)
  - ‚úÖ Alertes sur baisse de recall en production

#### 4. Robustesse limit√©e
- **Probabilit√©** : üü° Moyenne
- **Impact** : √âchecs dans conditions non-standard
- **Cause** : Pas de tests sur variations (nuit, pluie, angles)
- **Mitigation** :
  - ‚úÖ Tests de robustesse sur datasets adversaires
  - ‚úÖ Entra√Ænement avec augmentations extr√™mes
  - ‚úÖ Ensemble de mod√®les (si budget le permet)

---

### üü† Risques M√©tier (MOYENS)

#### 5. Attentes client d√©√ßues
- **Probabilit√©** : üü° Moyenne
- **Impact** : Insatisfaction, perte de confiance
- **Cause** : "IA" √©voque performance parfaite
- **Mitigation** :
  - ‚úÖ Communiquer clairement les limitations (recall, conditions)
  - ‚úÖ D√©mos r√©alistes avec cas d'√©chec
  - ‚úÖ SLA avec garanties mesurables (ex: mAP > 0.65)

#### 6. Conformit√© RGPD
- **Probabilit√©** : üü° Moyenne si d√©ploiement EU
- **Impact** : Amendes, blocage l√©gal
- **Cause** : D√©tection de personnes = donn√©es personnelles
- **Mitigation** :
  - ‚úÖ Anonymisation des d√©tections (pas de reconnaissance faciale)
  - ‚úÖ Politique de r√©tention des images
  - ‚úÖ Audit RGPD avant d√©ploiement

#### 7. Co√ªt de maintenance sous-estim√©
- **Probabilit√©** : üü¢ Faible
- **Impact** : Budget d√©pass√©
- **Cause** : Retraining fr√©quent si drift √©lev√©
- **Mitigation** :
  - ‚úÖ Budget MLOps d√©di√© (monitoring, retraining)
  - ‚úÖ Automatisation du pipeline

---

### üü¢ Risques Op√©rationnels (FAIBLES)

#### 8. Disponibilit√© du service
- **Probabilit√©** : üü¢ Faible
- **Impact** : Interruption de service
- **Cause** : Mod√®le l√©ger, infrastructure simple
- **Mitigation** :
  - ‚úÖ D√©ploiement redondant (load balancer)
  - ‚úÖ Healthchecks automatiques

---

### üìã Matrice de Risques - Synth√®se

| Risque | Probabilit√© | Impact | Priorit√© | Status |
|--------|-------------|--------|----------|--------|
| Precision catastrophique | üî¥ R√©alis√© | üî¥ Critique | üî• BLOQUANT | ‚ùå Non r√©solu |
| Faux positifs massifs | üî¥ R√©alis√© | üî¥ Critique | üî• BLOQUANT | ‚ùå 99% fausses d√©tections |
| Surapprentissage | üî¥ Tr√®s √©lev√©e | üî¥ √âlev√© | üî• CRITIQUE | ‚ùå 128 images seulement |
| Dataset Shift | üî¥ √âlev√©e | üî¥ √âlev√© | üî• CRITIQUE | ‚ö†Ô∏è √Ä traiter |
| Syst√®me inutilisable | üî¥ R√©alis√© | üî¥ Critique | üî• BLOQUANT | ‚ùå Ratio 1:113 |
| Attentes client d√©√ßues | üî¥ Certaine | üî¥ √âlev√© | üî• CRITIQUE | ‚ùå In√©vitable |

**Conclusion risques** : 6/6 risques critiques identifi√©s, dont 3 D√âJ√Ä R√âALIS√âS. Le mod√®le est dans un √©tat d'√©chec total.

---

## üéØ CHOIX FINAL

### D√©cision : ‚ùå **REJET - Ne pas promouvoir vers STAGING**

### üö® Justification du REJET

Le run **`87b38ef6c1c34c78935231ff929cafc9`** pr√©sente un **d√©faut r√©dhibitoire** qui le rend **totalement inutilisable** en l'√©tat :

#### üî¥ Probl√®me critique :
- **Precision = 0.87%** : Pour 1 vraie d√©tection, le mod√®le g√©n√®re 113 fausses alarmes
- **Ratio Precision/Recall = 1:93** : D√©s√©quilibre extr√™me et inacceptable
- **Cons√©quence** : Le syst√®me submergerait les utilisateurs de fausses d√©tections

#### Exemple concret :
```
Vid√©o de 1 heure avec 10 personnes r√©elles :
- Vraies d√©tections : 8 personnes (recall 81.6%)
- Fausses d√©tections : 904 fant√¥mes (precision 0.87%)
‚Üí Ratio signal/bruit : 1/113 = INUTILISABLE
```

---

### üîç Diagnostic du probl√®me

| Cause identifi√©e | Impact | Probabilit√© |
|------------------|--------|-------------|
| **Seuil de confiance trop bas** | D√©tections massives avec faible certitude | üî¥ Tr√®s √©lev√©e |
| **Dataset ultra-r√©duit (128 img)** | Manque d'exemples n√©gatifs | üî¥ √âlev√©e |
| **Seulement 3 epochs** | Pas de calibration correcte | üî¥ √âlev√©e |
| **Pas d'optimisation post-training** | Seuil non ajust√© au cas d'usage | üî¥ √âlev√©e |

---

### ‚úÖ Points positifs √† conserver

Malgr√© le rejet, le run d√©montre certains acquis :
1. ‚úÖ **Infrastructure fonctionnelle** : MLflow + DVC + Docker op√©rationnels
2. ‚úÖ **Recall excellent** : 81.6% prouve que le mod√®le "voit" les personnes
3. ‚úÖ **Reproductibilit√© valid√©e** : Stabilit√© entre seeds (1 vs 42)
4. ‚úÖ **Pipeline complet** : De l'entra√Ænement au tracking fonctionne

---

### üîß Actions correctives OBLIGATOIRES

Avant toute nouvelle tentative de promotion :

#### üéØ Priorit√© 1 : Corriger la pr√©cision (Bloquant)

| Action | Objectif | M√©thode |
|--------|----------|---------|
| **Augmenter seuil de confiance** | Precision > 50% | Tester seuils 0.3, 0.5, 0.7 avec validation |
| **R√©entra√Æner avec plus d'epochs** | Convergence compl√®te | Minimum 50 epochs (id√©al: 100+) |
| **Dataset plus large** | Exemples n√©gatifs suffisants | COCO complet (5000+ images "person") |
| **NMS ajust√©** | R√©duire d√©tections dupliqu√©es | Optimiser IoU threshold |

#### üéØ Priorit√© 2 : Validation robuste

| Action | Crit√®re de succ√®s |
|--------|-------------------|
| Tester sur validation set externe | mAP@50 > 0.50 |
| Courbe Precision-Recall | Trouver point optimal |
| Tests A/B seuils de confiance | S√©lectionner meilleur compromis |
| Matrice de confusion d√©taill√©e | Analyser types d'erreurs |


---

### üé¨ Prochaines actions IMM√âDIATES (cette semaine)

#### Action 1 : R√©entra√Ænement urgent
```bash
# Commande √† ex√©cuter
python -m src.train_cv \
  --epochs 100 \
  --imgsz 640 \
  --conf-thres 0.5 \
  --data coco_person_full.yaml \
  --exp-name cv_yolo_v2_corrected
```
**Responsable** : Data Scientist  
**Deadline** : 25/11/2025  
**Tracking** : Nouveau run MLflow

#### Action 2 : Analyse du seuil optimal
```python
# Script d'optimisation
from sklearn.metrics import precision_recall_curve
# Tester seuils de 0.1 √† 0.9
# Tracer courbe et s√©lectionner point maximal F1
```
**Responsable** : ML Engineer  
**Deadline** : 26/11/2025

#### Action 3 : Documentation des le√ßons apprises
- [ ] Documenter pourquoi 3 epochs est insuffisant
- [ ] Ajouter checklist "metrics sanity check" avant promotion
- [ ] Cr√©er alerte automatique si precision < 10%

---

### üìä M√©triques minimales pour r√©essayer une promotion

| KPI | Seuil MINIMUM | Valeur Actuelle | Status |
|-----|---------------|-----------------|--------|
| **Precision** | > 50% | **0.87%** | ‚ùå √âCHEC |
| **mAP@50** | > 0.50 | **0.276** | ‚ùå √âCHEC |
| **Recall** | > 70% | **81.6%** | ‚úÖ OK |
| **F1-Score** | > 0.60 | **0.0173** | ‚ùå √âCHEC |
| **Epochs** | > 50 | **3** | ‚ùå √âCHEC |

**Verdict global** : 1/5 crit√®res valid√©s ‚Üí **REJET JUSTIFI√â**

---

### üí° Alternative : Promotion conditionnelle en "RESEARCH"

Si vous souhaitez malgr√© tout tracker ce mod√®le :

**Option** : Cr√©er un stage "RESEARCH" ou "FAILED" dans Model Registry
- **Objectif** : Garder trace des √©checs pour apprentissage
- **Tags** : `status:rejected`, `reason:low-precision`, `for:educational-purposes`
- **Usage** : Documentation interne, ne JAMAIS d√©ployer

```python
# Enregistrement en mode "Failed Experiment"
mlflow.register_model(
    model_uri=f"runs:/{run_id}/model",
    name="yolo-person-detector-FAILED-v1",
    tags={"precision": "0.0087", "status": "rejected"}
)
```

---

### üö¶ Conditions de promotion vers PRODUCTION

Le mod√®le **NE PEUT PAS** passer en production sans valider ces crit√®res :

#### ‚úÖ Crit√®res obligatoires (Bloquants)

| # | Crit√®re | Status | Deadline |
|---|---------|--------|----------|
| 1 | R√©entra√Ænement sur COCO complet (classe person, min 5000 images) | ‚ùå TODO | Semaine 1 |
| 2 | mAP@50 sur validation set externe > 0.70 | ‚ùå TODO | Semaine 2 |
| 3 | Tests de robustesse (nuit, pluie, occlusions) - recall > 60% | ‚ùå TODO | Semaine 2 |
| 4 | Impl√©mentation monitoring en temps r√©el (mAP, latence, drift) | ‚ùå TODO | Semaine 3 |
| 5 | Audit RGPD si d√©ploiement EU | ‚ùå TODO | Semaine 4 |
| 6 | Tests A/B vs baseline sur donn√©es r√©elles (2 semaines minimum) | ‚ùå TODO | Semaine 6 |

#### üéØ Crit√®res recommand√©s (Non-bloquants)

| # | Crit√®re | Priorit√© |
|---|---------|----------|
| 7 | Pipeline de retraining automatique (mensuel) | Haute |
| 8 | Comparaison avec YOLOv8s (small) pour √©valuer gain pr√©cision | Moyenne |
| 9 | Impl√©mentation fallback detector (si recall < seuil) | Haute |
| 10 | Dashboard de monitoring production (Grafana + Prometheus) | Moyenne |


---

### üìä M√©triques de succ√®s pour passage en PRODUCTION

| KPI | Seuil Minimum | Valeur Actuelle | Valeur Cible |
|-----|---------------|-----------------|--------------|
| **mAP@50 (validation)** | > 0.70 | _[√Ä mesurer]_ | > 0.80 |
| **Recall** | > 0.65 | _[√Ä mesurer]_ | > 0.75 |
| **Precision** | > 0.70 | _[√Ä mesurer]_ | > 0.80 |
| **Latence (p95)** | < 50ms | ~15ms | < 30ms |
| **Throughput** | > 30 FPS | ~60 FPS | > 40 FPS |
| **Uptime** | > 99% | N/A | > 99.5% |

---

## üì∏ Annexes - R√©f√©rences MLflow

### Captures d'√©cran √† inclure
1. ‚úÖ **Liste compl√®te des runs** (tableau avec m√©triques)
2. ‚úÖ **√âcran de comparaison actuel** (Parallel Coordinates Plot)
3. ‚è≥ **M√©triques d√©taill√©es** (√† capturer en scrollant)
4. ‚è≥ **Artefacts du run s√©lectionn√©** :
   - `results.png` (courbes d'entra√Ænement)
   - `confusion_matrix.png`
   - `predictions.png` (exemples de d√©tections)

### Liens MLflow
- **UI MLflow** : http://localhost:5000
- **Exp√©rience** : cv_yolo_tiny

---

## üìù Notes et Observations

### Points positifs identifi√©s
- Stabilit√© entre seeds diff√©rents (1 vs 42)
- Temps d'entra√Ænement tr√®s rapide
- Infrastructure MLflow + DVC + MinIO fonctionne parfaitement

### Points d'attention
- Dataset trop petit pour conclusions d√©finitives
- N√©cessit√© de validation externe urgente
- Monitoring production √† impl√©menter avant go-live

### Le√ßons apprises
- MLflow tracking tr√®s utile pour comparaisons rapides
- DVC essentiel pour reproductibilit√© dataset
- Importance de d√©finir crit√®res de production AVANT entra√Ænement

---

## üìö R√©f√©rences

- [MLflow Documentation](https://mlflow.org/docs/latest/index.html)
- [YOLOv8 Official Docs](https://docs.ultralytics.com/)
- [COCO Dataset](https://cocodataset.org/)
- [DVC Documentation](https://dvc.org/doc)

---

**Document g√©n√©r√© le** : 23 novembre 2025  
**Version** : 1.0  
**Auteur** : Raed Mohamed Amine Hamrouni 
